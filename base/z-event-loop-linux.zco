/* ZCO - Cross-platform Application Framework
 * Copyright (C) 2014  Rawnak Jahan Syeda
 *
 * z-event-loop-linux.zco: Event loop based around epoll
 * This file is part of ZCO.
 *
 * This library is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * ZCO is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public License
 * along with ZCO.  If not, see <http://www.gnu.org/licenses/>.
 */

%h{
#include <z-object.h>
#include <z-event-loop-protected.h>
#include <z-in-out-multiplexer.h>
#include <sys/epoll.h>

/* We require Linux kernel 2.6.37 or higher. The epoll_wait implementation for prior versions
   of the kernel assume an infinite wait time when the specified wait time is larger than
   LONG_MAX / HZ */
#define Z_EVENT_LOOP_MAX_EVENTS 5 

typedef struct epoll_event events_t[Z_EVENT_LOOP_MAX_EVENTS];

%}

%{
#include <z-bind.h>

#define _GNU_SOURCE
#include <unistd.h>

#include <stdio.h>
#include <unistd.h>
#include <fcntl.h>
#include <errno.h>

#define INT_TO_PTR(x) ((void *) ((unsigned long) (x)))
#define PTR_TO_INT(x) ((int64_t) ((long) (x)))

struct ZEventBind
{
        ZBind *bind;
        int is_active;
};
typedef struct ZEventBind ZEventBind;

%}

class ZEventLoopLinux : ZEventLoop, ZInOutMultiplexer
{
        private ZMap *fd_map;
        private ZMap *self_pipe_listeners;
        private ZInOut *ep_handle;
        private ZInOut *pipe_in;
        private ZInOut *pipe_out;

	public Self *new(struct zco_context_t *ctx, ZMemoryAllocator *allocator)
	{
		Self *self = GET_NEW(ctx, allocator);
		return self;
	}

        private void event_task_destroy(void *event_task, Self *self)
        {
                ZMemoryAllocator *allocator = CTX_FROM_OBJECT(self)->fixed_allocator;
                z_memory_allocator_deallocate_by_size(allocator, event_task, sizeof(ZEventBind));
        }

        private ZMap * get_listeners(Self *self, ZInOut *inout, int no_create)
        {
                ZMapIter *it = z_map_find(selfp->fd_map, inout);
                ZMap *list;

                if (it) {
                        list = z_map_get_value(selfp->fd_map, it);
                        z_object_unref(Z_OBJECT(it));
                        z_object_ref(Z_OBJECT(list));
                        return list;
                }

                if (no_create)
                        return NULL;

                list = z_map_new(CTX_FROM_OBJECT(self), ALLOCATOR_FROM_OBJECT(self));
                z_map_assign(selfp->fd_map, inout, list);

                z_map_set_compare(list, map_compare);
                z_map_set_key_destruct(list, (ZMapItemCallback) z_object_unref);
                z_map_set_value_destruct(list, (ZMapItemCallback) event_task_destroy);
                z_map_set_userdata(list, self);

                struct epoll_event event;
                event.data.ptr = list;
                event.events = EPOLLIN | EPOLLOUT | EPOLLRDHUP | EPOLLPRI | EPOLLET;

                if (z_in_out_epoll_control(selfp->ep_handle, EPOLL_CTL_ADD, inout, &event) == -1) {
                        perror("epoll_ctl");
                        abort();
                }

                z_object_ref(Z_OBJECT(list));
                return list;
        }

        private int map_compare(ZMap *map, const void *a, const void *b)
        {
                return PTR_TO_INT(a) - PTR_TO_INT(b);
        }

	init(Self *self)
	{
                /* Create an epoll file descriptor */
                selfp->ep_handle = z_in_out_new(CTX_FROM_OBJECT(self), ALLOCATOR_FROM_OBJECT(self));
                int ep_fd = epoll_create1(0);
                assert(ep_fd >= 0);
                z_in_out_set_fd(selfp->ep_handle, ep_fd);

                /* Create a pipe to send tasks into guest thread */
                int pipe_fds[2];
                assert(pipe(pipe_fds) == 0);

                selfp->pipe_out = z_in_out_new(CTX_FROM_OBJECT(self), ALLOCATOR_FROM_OBJECT(self));
                z_in_out_set_fd(selfp->pipe_out, pipe_fds[0]);

                selfp->pipe_in = z_in_out_new(CTX_FROM_OBJECT(self), ALLOCATOR_FROM_OBJECT(self));
                z_in_out_set_fd(selfp->pipe_in, pipe_fds[1]);

                /* Set file descriptors to non-blocking mode */
                z_in_out_set_flags(selfp->pipe_out, O_NONBLOCK);

                selfp->fd_map = z_map_new(CTX_FROM_OBJECT(self), ALLOCATOR_FROM_OBJECT(self));
                z_map_set_compare(selfp->fd_map, map_compare);
                z_map_set_value_destruct(selfp->fd_map, (ZMapItemCallback) z_object_unref);

                /* Subscribe the output of the pipe to epoll */
                selfp->self_pipe_listeners = get_listeners(self, selfp->pipe_out, 0);
	}

        override(ZObject) void dispose(ZObject *object)
        {
                Self *self = (Self *) object;

                /* Wait for thread to complete */
                z_event_loop_quit(Z_EVENT_LOOP(self));
                z_event_loop_join(Z_EVENT_LOOP(self));

                z_object_unref(Z_OBJECT(selfp->self_pipe_listeners));

                /* Clear the fd_map. It's not enough to release the reference to the map because it's possible
                   for the garbage collector to lazily remove the items. Given that the item destructor requires
                   the presence of 'self', we must clear the map now */
                z_map_clear(selfp->fd_map);
                z_object_unref(Z_OBJECT(selfp->fd_map));

                /* pipe_out will be unsubscribed from epoll once the file descriptor is closed */
                z_object_unref(Z_OBJECT(selfp->pipe_in));
                z_object_unref(Z_OBJECT(selfp->pipe_out));

                z_object_unref(Z_OBJECT(selfp->ep_handle));

                PARENT_HANDLER(object);
        }

        override(ZEventLoop) void reload_runqueue(ZEventLoop *ev)
        {
                Self *self = (Self *) ev;

                ZTask *tasks[Z_EVENT_LOOP_MAX_EVENTS];
                struct zco_context_t *ctx = CTX_FROM_OBJECT(self);
                ssize_t nbytes;

                while(1) {
                        nbytes = z_in_out_read_buffer(selfp->pipe_out, &tasks[0], sizeof(tasks));

                        if (nbytes == -1) {
                                if (errno == EAGAIN)
                                        break;

                                perror("read");
                                continue;
                        }

                        int i;
                        int count = nbytes / sizeof(ZTask *);

                        for (i=0; i<count; ++i) {
                                ZTask *task = tasks[i];
                                z_event_loop_add_task_to_runqueue(Z_EVENT_LOOP(self), task);
                        }

                };
        }

        private int64_t convert_monotonic_to_timeout(Self *self, uint64_t monotonic)
        {
                /* During the conversion from nanoseconds to milliseconds, the
                   value is rounded up to the nearest integer */
                uint64_t monotonic_ns = z_event_loop_get_monotonic_time(); 
                int64_t timeout_ms = ((int64_t) monotonic - (int64_t) monotonic_ns + 999999) / 1000000;
                return (timeout_ms >= 0)? timeout_ms : 0;
        }

        override(ZEventLoop) void wait_for_signal(ZEventLoop *ev, uint64_t next_task_time)
        {
                Self *self = (Self *) ev;
                int timeout_ms;
                int self_pipe_found;

                do {
                        if (next_task_time)
                                timeout_ms = (int) convert_monotonic_to_timeout(self, next_task_time);
                        else
                                timeout_ms = -1;

                        /* No need to call epoll_pwait if we already know that the next scheduled
                           is ready to be executed. */
                        if (timeout_ms == 0)
                                return;

                        /* epoll_pwait first calls sigprocmask to set the signal mask to the
                           specified 'sigmask', calls the standard epoll_wait() function and
                           then resets the signal mask with another call to sigprocmask, all
                           atomically. although we are not supposed to use sigprocmask in a
                           multi-threaded application, we can still get away with it as long
                           as we don't block the SIGCANCEL and SIGSETXID signals. */
                        sigset_t sigmask;
                        struct epoll_event ep_events[Z_EVENT_LOOP_MAX_EVENTS];
                        sigemptyset(&sigmask);

                        self_pipe_found = 0;
                        int nfds = z_in_out_epoll_pwait_event(selfp->ep_handle, ep_events, Z_EVENT_LOOP_MAX_EVENTS, timeout_ms, &sigmask);
                        int i;

                        for (i=0; i<nfds; ++i) {
                                struct epoll_event *ev = ep_events + i;
                                ZMap *list = (ZMap *) ev->data.ptr;

                                if (list == selfp->self_pipe_listeners) {
                                        self_pipe_found = 1;

                                } else {
                                        /* Invoke the tasks that are not scheduled for removal. If the task is scheduled
                                           to be removed, it is removed and we continue with the rest of the subscription list */
                                        ZMapIter *it = z_map_get_begin(list);
                                        ZMapIter *end = z_map_get_end(list);

                                        while (!z_map_iter_is_equal(it, end)) {
                                                ZEventBind *event_bind = (ZEventBind *) z_map_get_value(list, it);

                                                if (event_bind->is_active) {
                                                        z_map_iter_increment(it);
                                                } else {
                                                        z_map_erase1_inc(list, &it);
                                                        z_object_unref(Z_OBJECT(end));
                                                        end = z_map_get_end(list);
                                                        continue;
                                                }

                                                /* Invoke the task */
                                                ZBind *new_task = z_bind_new(CTX_FROM_OBJECT(self), ALLOCATOR_FROM_OBJECT(self));
                                                z_bind_assign(new_task, event_bind->bind);
                                                z_bind_append_uint32(new_task, convert_flags(ev->events));
                                                z_bind_invoke(new_task);
                                                z_object_unref(Z_OBJECT(new_task));
                                        }

                                        z_object_unref(Z_OBJECT(end));
                                        z_object_unref(Z_OBJECT(it));

                                        /* Second pass through the subscription list to remove what we missed */
                                        it = z_map_get_begin(list);
                                        end = z_map_get_end(list);

                                        while (!z_map_iter_is_equal(it, end)) {
                                                ZEventBind *event_bind = (ZEventBind *) z_map_get_value(list, it);

                                                if (event_bind->is_active) {
                                                        z_map_iter_increment(it);
                                                } else {
                                                        z_map_erase1_inc(list, &it);
                                                        z_object_unref(Z_OBJECT(end));
                                                        end = z_map_get_end(list);
                                                }
                                        }

                                        z_object_unref(Z_OBJECT(end));
                                        z_object_unref(Z_OBJECT(it));
                                }
                        }

                } while (!self_pipe_found);
        }

        private uint32_t convert_flags(uint32_t flag)
        {
                uint32_t new_flag = 0;

                /* EPOLLIN is fired when data is available for reading */
                if (flag & EPOLLIN)           new_flag |= IO_MULTIPLEXER_IN;

                /* EPOLLPRI is fired when there is a high priority data
                   available for reading. This data will skip ahead of the
                   incoming queue */
                if (flag & EPOLLPRI)          new_flag |= IO_MULTIPLEXER_PRI;

                /* EPOLLOUT is fired when the file descriptor is ready to
                   accept write operations */
                if (flag & EPOLLOUT)          new_flag |= IO_MULTIPLEXER_OUT;

                /* TODO: Please document the following flags */
                if (flag & EPOLLRDNORM)       new_flag |= IO_MULTIPLEXER_RDNORM;
                if (flag & EPOLLRDBAND)       new_flag |= IO_MULTIPLEXER_RDBAND;
                if (flag & EPOLLWRNORM)       new_flag |= IO_MULTIPLEXER_WRNORM;
                if (flag & EPOLLWRBAND)       new_flag |= IO_MULTIPLEXER_WRBAND;
                if (flag & EPOLLMSG)          new_flag |= IO_MULTIPLEXER_MSG;
                if (flag & EPOLLWAKEUP)       new_flag |= IO_MULTIPLEXER_WAKEUP;

                /* EPOLLERR is fired when an error occurs */
                if (flag & EPOLLERR)          new_flag |= IO_MULTIPLEXER_ERR;

                /* EPOLLHUP is fired when the file descriptor is released.
                   Note that a hang up is not an error unless it happens before
                   EPOLLRDHUP.

                   Please see fs/eventfd.c in the Linux kernel 3.0 source tree
                   for details */
                if (flag & EPOLLHUP)          new_flag |= IO_MULTIPLEXER_HUP;

                /* EPOLLRDHUP is fired for a socket file descriptor when the
                   remote peer half-closes its TCP connection */
                if (flag & EPOLLRDHUP)        new_flag |= IO_MULTIPLEXER_RDHUP;

                return new_flag;
        }

	override(ZInOutMultiplexer)
        int subscribe_fd(ZObject *io_multiplexer, ZInOut *inout, ZBind *task)
        {
                Self *self = (Self *) io_multiplexer;

                /* Wrap the task with a ZEventBind object */
                ZMemoryAllocator *allocator = CTX_FROM_OBJECT(self)->fixed_allocator;
                ZEventBind *event_bind = (ZEventBind *) z_memory_allocator_allocate(allocator, sizeof(ZEventBind));
                event_bind->bind = task;
                event_bind->is_active = 1;

                /* Insert the ZEventBind object into the listeners map */
                ZMap *listeners = get_listeners(self, inout, 0);
                int rc = z_map_insert(listeners, task, event_bind);
                z_object_unref(Z_OBJECT(listeners));

                if (rc == 0)
                        z_object_ref(Z_OBJECT(task));
                else
                        z_memory_allocator_deallocate_by_size(allocator, event_bind, sizeof(ZEventBind));

                return rc;
        }

	override(ZInOutMultiplexer)
        int unsubscribe_fd(ZObject *io_multiplexer, ZInOut *inout, ZBind *task)
        {
                Self *self = (Self *) io_multiplexer;
                ZMap *listeners = get_listeners(self, inout, 1);

                if (!listeners)
                        return -EINVAL;

                ZMapIter *it = z_map_find(listeners, task);
                z_object_unref(Z_OBJECT(listeners));

                if (it) {
                        ZEventBind *event_bind = (ZEventBind *) z_map_get_value(listeners, it);
                        event_bind->is_active = 0;
                        z_object_unref(Z_OBJECT(it));
                        return 0;
                }

                return -EINVAL;
        }

        override(ZEventLoop) int add_to_task_queue(ZEventLoop *ev, ZTask *task)
        {
                Self *self = (Self *) ev;

                /* Send the address of the task to the guest thread through the pipe */
                int rc = z_in_out_write_buffer(selfp->pipe_in, &task, sizeof(ZTask *));
                return (rc < 0)? -errno : 0;
        }

}

