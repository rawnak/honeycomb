/* ZCO - Cross-platform Application Framework
 * Copyright (C) 2014  Rawnak Jahan Syeda
 *
 * z-event-loop.zco: Event loop interface
 * This file is part of ZCO.
 *
 * This library is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Lesser General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * ZCO is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public License
 * along with ZCO.  If not, see <http://www.gnu.org/licenses/>.
 */

%h{
#include <z-map.h>
#include <z-closure.h>
#include <z-bind.h>
#include <signal.h>

%}

%{
#include <z-value.h>
#include <stdint.h>
#include <assert.h>
#include <stdio.h>

/* In an application, the first thread (main thread) will create a zco context. Lets call this
   the main context. The main thread can then create one or several zco contexts, each with an
   instance of ZEventLoop. Lets call these contexts the worker contexts. The ZEventLoop object
   will be under the worker context but, unlike other ZObject derived classes, some of its methods
   will be thread-safe.

   get_is_current() will return TRUE if the event loop is operating under the calling thread.

   run() will start the event loop in a new thread. This is not a blocking call since the loop
   will run on a new thread.

   post_task() will push a task described by a Bind object onto the context. The task will be
   scheduled to run after the specified timeout period. If a timeout of 0 is specified, it will
   run as soon as possible.

   quit() will push a QUIT task to the event loop. This task will set a flag so the event loop
   no longer waits for a new task. The event loop will still process any remaining tasks that
   are in the queue but it will not accept new tasks.
 */

#define INT_TO_PTR(x) ((void *) ((unsigned long) (x)))
#define PTR_TO_INT(x) ((int64_t) ((long) (x)))
%}

class ZEventLoop : ZObject
{
        private ZBind *quit_task;

        private pthread_t thread;
        private pthread_cond_t schedule_cond;
        private pthread_mutex_t queue_lock;

        /* This thread-unsafe queue is only accessed by the guest thread. It maps
           [the execution time for the task] => [task]. */
        private ZMap *run_queue;

        /* This thread-unsafe queue is only read by the guest thread. It contains a
           list of tasks that was previously written to on the incoming queue. These
           tasks are moved the run queue by the guest thread */
        private ZBindData *pending_queue;

        /* This thread-safe queue is written to by the host thread. The guest thread
           will periodically change the pointer to point to a "new" queue */
        private ZBindData *incoming_queue;

        /* This flag is written by do_quit(), and it's read by thread_main(),
           post_task(), and quit().

           The do_quit() function is a callback that is called from within thread_main().
           Since both functions operate on the same thread, there shouldn't be any
           race condition between them.

           The post_task(), and quit() function checks the is_done flag to determine
           if it should add more tasks into the queue. It's possible to have a race
           condition such that when it checks the value of the flag, it is clear but
           when it actually adds a task into the queue, the value is set. This is an
           acceptable race condition and it's ok for thread_main() to process tasks
           that have been scheduled after the 'quit' task is scheduled. Eventually the
           is_done flag will be recognized as set (if a termination is scheduled) and
           no more tasks will be added to the queue - which will allow thread_main()
           to exit gracefully. */
        private volatile sig_atomic_t is_done;

        /* This flag is written by two function thread_main(), run() and it's read by
           three functions run(), post_task(), quit(). 

           The thread_main() function can only run after the run() function is called
           so there should not be a race condition to write on the flag by these two
           functions.

           The thread_main() function will not modify the flag unless the event loop
           is scheduled to be terminated. If the application already called quit() to
           schedule the termination, subsequent calls to post_task() and quit() will be
           a no-op since the is_done flag is set. This will prevent post_task() and quit()
           from reading the is_running flag since thread_main() can clear the flag any
           moment.  */
        private volatile sig_atomic_t is_running;

        private int map_compare(ZMap *map, const void *a, const void *b)
        {
#if __WORDSIZE >= 64
                return PTR_TO_INT(a) - PTR_TO_INT(b);
#else
                return *((uint64_t *) a) - *((uint64_t *) b);
#endif
        }

        private void runqueue_key_destroy(void *item, Self *self)
        {
                ZMemoryAllocator *allocator = CTX_FROM_OBJECT(self)->fixed_allocator;
                z_memory_allocator_deallocate_by_size(allocator, item, sizeof(uint64_t));
        }

        private void runqueue_value_destroy(ZBind *task, Self *self)
        {
                ZMemoryAllocator *allocator = CTX_FROM_OBJECT(self)->fixed_allocator;
                ZBindData *data = z_bind_get_data_ptr(task);
                z_memory_allocator_deallocate_by_size(allocator, data, sizeof(ZBindData));
                z_object_unref(Z_OBJECT(task));
        }

        init(Self *self)
        {
                selfp->is_done = 0;
                selfp->is_running = 0;

                struct zco_context_t *ctx = CTX_FROM_OBJECT(self);
                ZMemoryAllocator *allocator = ALLOCATOR_FROM_OBJECT(self);

                /* Create a bind closure for the quit task */
                selfp->quit_task = z_bind_new(ctx, allocator);
                z_bind_set_handler(selfp->quit_task, (ZBindHandler) zco_context_do_quit);
                z_bind_set_timeout(selfp->quit_task, 0);
                z_bind_append_ptr(selfp->quit_task, self);

                /* Initialize task queues */
                selfp->run_queue = z_map_new(ctx, allocator);
                z_map_set_compare(selfp->run_queue, map_compare);
                z_map_set_userdata(selfp->run_queue, self);

#if __WORDSIZE < 64
                z_map_set_key_destruct(selfp->run_queue, (ZMapItemCallback) runqueue_key_destroy);
#endif
                z_map_set_value_destruct(selfp->run_queue, (ZMapItemCallback) runqueue_value_destroy);

                selfp->pending_queue = NULL;
                selfp->incoming_queue = NULL;

                /* Initialize locks */
                pthread_mutex_init(&selfp->queue_lock, NULL);

                /* Initialize condition variables */
                pthread_cond_init(&selfp->schedule_cond, NULL);
        }

        private void delete_queue(Self *self, ZBindData **queue)
        {
                ZMemoryAllocator *allocator = CTX_FROM_OBJECT(self)->ts_fixed_allocator;
                ZBindData *p = *queue;

                while (p) {
                        ZBindData *next = p->next;
                        z_memory_allocator_deallocate_by_size(allocator, p, sizeof(ZBindData));
                        p = next;
                }

                *queue = NULL;
        }

        override(ZObject) void reset(ZObject *object)
        {
                /* We never anticipate reusing a ZEventLoop object */
                abort();
        }

	override(ZObject) void dispose(ZObject *object)
	{
		Self *self = (Self *) object;

                quit(self);
                z_object_unref(Z_OBJECT(selfp->quit_task));

                /* Wait for thread to complete */
                pthread_join(selfp->thread, NULL);
                selfp->is_done = 0;

                delete_queue(self, &selfp->incoming_queue);
                delete_queue(self, &selfp->pending_queue);

                pthread_mutex_destroy(&selfp->queue_lock);

		PARENT_HANDLER(object);
	}

	public Self *new(struct zco_context_t *ctx, ZMemoryAllocator *allocator)
	{
		Self *self = GET_NEW(ctx, allocator);
		return self;
	}

        public int is_current
        {
                get
                {
                        return pthread_equal(pthread_self(), selfp->thread);
                }
        }

        private void reload_pending_queue(Self *self)
        {
                /* Ensure pending queue is empty */
                assert(!selfp->pending_queue);

                /* Swap the pending queue and incoming queue */
                ZBindData *temp = selfp->pending_queue;
                selfp->pending_queue = selfp->incoming_queue;
                selfp->incoming_queue = temp;
        }

        private void thread_main(Self *self)
        {
                int is_running = 1;
                struct zco_context_t *ctx = CTX_FROM_OBJECT(self);
                ZMemoryAllocator *allocator = ALLOCATOR_FROM_OBJECT(self);
                ZMemoryAllocator *data_allocator = ctx->ts_fixed_allocator;

                while (is_running) {
                        /* Move tasks from the pending queue into the run queue */
                        ZBindData *queue = selfp->pending_queue; 
                        while (queue) {
                                ZBind *task = z_bind_new(ctx, allocator);
                                z_bind_set_data_ptr(task, queue);

#if __WORDSIZE >= 64
                                /* For 64-bit systems, we store the time inforation inside the pointer value. This allows
                                   us to eliminate an allocation */

                                while (z_map_insert(selfp->run_queue, INT_TO_PTR(queue->timeout), task) == -1) {
                                        /* In the rare case when two tasks where scheduled to run at the same time,
                                           we delay one of the tasks by 1ns to ensure all keys in the map are unique */
                                        ++queue->timeout;
                                }
#else
                                /* For 32-bit systems (or less), we allocate an 8-byte buffer to store the time information
                                   and stor ethe address to this buffer in the pointer value. */

                                uint64_t *task_time = z_memory_allocator_allocate(ctx->fixed_allocator, sizeof(uint64_t));
                                *task_time = queue->timeout;

                                while (z_map_insert(selfp->run_queue, task_time, task) == -1) {
                                        /* In the rare case when two tasks where scheduled to run at the same time,
                                           we delay one of the tasks by 1ns to ensure all keys in the map are unique */
                                        ++(*task_time);
                                }
#endif

                                queue = queue->next;
                        }

                        /* Compute the range of tasks that should be executed now */
                        uint64_t current_time = get_current_time();
                        ZMapIter *it, *end;
                        it = z_map_get_begin(selfp->run_queue);

#if __WORDSIZE >= 64
                        end = z_map_upper_bound(selfp->run_queue, INT_TO_PTR(current_time));
#else
                        end = z_map_upper_bound(selfp->run_queue, &current_time);
#endif

                        /* Iterate through the run queue and execute the tasks that
                           are scheduled to run now */
                        while (!z_map_iter_is_equal(it, end)) {
                                ZBind *task = z_map_get_value(selfp->run_queue, it);
                                z_bind_invoke(task);
                                z_map_iter_increment(it);
                        }

                        /* Remove the tasks from the queue that have been executed */
                        z_map_erase(selfp->run_queue, NULL, end);

                        z_object_unref(Z_OBJECT(it));
                        z_object_unref(Z_OBJECT(end));

                        /* All tasks in the pending queue has been moved over to the run queue. Lets
                           swap the pending queue and incoming queue so we can execute newly added tasks
                           that exists in the incoming queue.
                         
                           We should do this as late as possible so that the incoming queue has a better
                           chaance of having some tasks */
                        selfp->pending_queue = NULL;

                        /* Hold the queue lock */
                        pthread_mutex_lock(&selfp->queue_lock);

                        /* Pick up the new queue. If new tasks are available, we won't wait
                           for a signal and just repeat the loop */
                        reload_pending_queue(self);

                        if (selfp->pending_queue) {
                                goto release_lock;
                        }

                        uint64_t next_task_time;

                        if (z_map_get_is_empty(selfp->run_queue)) {
                                /* If no tasks are scheduled to run, we don't know how long we should
                                   wait for a signal. We denote a non-timed wait with next_task_time=0 */
                                next_task_time = 0;

                                /* If the is_done flag is also set, we release the locks and exit the loop */
                                if (selfp->is_done) {
                                        is_running = 0;
                                        goto release_lock;
                                }

                        } else {
                                /* Check the time of the next scheduled task in the run queue */
                                it = z_map_get_begin(selfp->run_queue);
#if __WORDSIZE >= 64
                                next_task_time = PTR_TO_INT(z_map_get_key(selfp->run_queue, it));
#else
                                next_task_time = *((uint64_t *) z_map_get_key(selfp->run_queue, it));
#endif
                                z_object_unref(Z_OBJECT(it));
                        }

                        if (next_task_time) {
                                struct timespec timeout;
                                timeout.tv_sec = next_task_time / 1000000000ul;
                                timeout.tv_nsec = next_task_time % 1000000000ul;

                                pthread_cond_timedwait(&selfp->schedule_cond, &selfp->queue_lock, &timeout);
                        } else {
                                pthread_cond_wait(&selfp->schedule_cond, &selfp->queue_lock);
                        }

                        reload_pending_queue(self);

release_lock:
                        /* Release the queue lock */
                        pthread_mutex_unlock(&selfp->queue_lock);
                }

                selfp->is_running = 0;
                z_object_unref(Z_OBJECT(selfp->run_queue));

                pthread_exit(0);
        }

        public void run(Self *self)
        {
                if (selfp->is_running)
                        return;

                selfp->is_running = 1;
                memset(&selfp->thread, 0, sizeof(pthread_t));
                pthread_create(&selfp->thread, NULL, (void * (*)(void*)) &thread_main, self);
        }

        private int is_active(Self *self)
        {
                /* It's optimal to check the is_done flag over is_running. The is_running flag
                   can be modified by the thread_main() function so there is a greater chance
                   of a cache miss if we read from it */
                if (selfp->is_done || !selfp->is_running)
                        return 0;

                return 1;
        }

        private uint64_t get_current_time()
        {
                struct timespec tp;
                clock_gettime(CLOCK_REALTIME, &tp);
                return ((uint64_t) tp.tv_sec) * 1000000000ul + tp.tv_nsec;
        }

        public void post_task(Self *self, ZBind *bind)
        {
                if (!is_active(self))
                        return;

                /* Use the thread-safe allocator to allocate memory for the raw closure */
                ZMemoryAllocator *allocator = CTX_FROM_OBJECT(self)->ts_fixed_allocator;
                ZBindData *data = z_memory_allocator_allocate(allocator, sizeof(ZBindData));

                /* Hold the incoming_queue lock */
                pthread_mutex_lock(&selfp->queue_lock);

                /* Normalize the timeout with a monotonic clock - Instead of
                   it being the time between now and the time the task is
                   scheduled to run, it will become the time between a
                   monotonic time and the time the task is scheduled to run */
                ZBindData *data_src = z_bind_get_data_ptr(bind);
                memcpy(data, data_src, sizeof(ZBindData));
                data->timeout += get_current_time();

                /* Prepend it into the incoming queue. We don't care
                   about the order of insertion into the incoming queue; The order of execution
                   is preserved because each task knows what time it should be executed. As
                   long as the tasks that are scheduled the earliest are executed first, the
                   order will be maintained */
                data->next = selfp->incoming_queue;
                selfp->incoming_queue = data;

                /* Send a signal that new work has been scheduled */
                pthread_cond_signal(&selfp->schedule_cond);

                /* Release the incoming_queue lock */
                pthread_mutex_unlock(&selfp->queue_lock);
        }

        private void zco_context_do_quit(ZBind *bind, Self *self)
        {
                selfp->is_done = 1;
        }

        /* We post a task to set the flag instead of setting the flag right here so that we
           wake up the event loop if it is sleeping */
        public void quit(Self *self)
        {
                if (!is_active(self))
                        return;

                /* Send a QUIT signal to the thread */
                post_task(self, selfp->quit_task);
        }

}

